{% set name = "oneDNN" %}
{% set version = "3.7.2" %}

package:
  name: onednn-split
  version: {{ version }}

source:
  url: https://github.com/oneapi-src/{{ name }}/archive/v{{ version }}.tar.gz
  sha256: 21068e8cd2bf4077916bf31452eab5ac9998e620e1b22630a88f79c334857a5c

build:
  number: 0

outputs:
  - name: onednn
    script: build-onednn.sh  # [not win]
    script: bld-onednn.bat  # [win]
    version: {{ version }}
    build:
      string: {{ dnnl_cpu_runtime }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}
      run_exports:
        - {{ pin_subpackage("onednn", max_pin="x") }}
      {% if dnnl_cpu_runtime != "omp" %}
      track_features:
        - onednn-{{ dnnl_cpu_runtime }}
      {% endif %}
    requirements:
      build:
        - cmake
        - ninja
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        - {{ compiler('dpcpp') }}  # [dnnl_cpu_runtime == "dpcpp"]
        - {{ stdlib("c") }}
        - llvm-openmp  # [osx]
      host:
        - tbb-devel  # [dnnl_cpu_runtime in ("tbb", "dpcpp")]
    about:
      home: https://github.com/oneapi-src/oneDNN
      license: Apache-2.0
      license_file:
        - THIRD-PARTY-PROGRAMS
        - LICENSE
      summary: oneAPI Deep Neural Network Library (oneDNN)
      description: |
        oneAPI Deep Neural Network Library (oneDNN) is an open-source
        cross-platform performance library of basic building blocks for deep
        learning applications.

        oneDNN is intended for deep learning applications and framework
        developers interested in improving application performance.
        Deep learning practitioners should use one of the applications
        enabled with oneDNN.

        {% if dnnl_cpu_runtime == "omp" %}
        In this package oneDNN is built with the OpenMP CPU runtime.
        {% elif dnnl_cpu_runtime == "tbb" %}
        In this package oneDNN is built with the TBB CPU runtime.
        {% elif dnnl_cpu_runtime == "threadpool" %}
        In this package oneDNN is built with the Threadpool CPU runtime.
        oneDNN requires the user to implement a Threadpool interface to enable
        the library to perform computations using multiple threads.
        {% elif dnnl_cpu_runtime == "dpcpp" %}
        In this package oneDNN is built with the DPC++ CPU and GPU runtimes.
        {% endif %}

        For more information please read oneDNN developer guide:
        https://oneapi-src.github.io/oneDNN/
    test:
      commands:
        - test -f ${PREFIX}/lib/libdnnl${SHLIB_EXT}  # [unix]
        - test -f ${PREFIX}/include/oneapi/dnnl/dnnl.h  # [unix]
        - if not exist %LIBRARY_PREFIX%\\bin\\dnnl.dll exit 1  # [win]
        - if not exist %LIBRARY_PREFIX%\\lib\\dnnl.lib exit 1  # [win]
        - if not exist %LIBRARY_PREFIX%\\include\\dnnl.h exit 1  # [win]

  - name: onednn-{{ dnnl_cpu_runtime_name }}
    version: {{ version }}
    build:
      string: {{ dnnl_cpu_runtime }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}
      run_exports:
        - {{ pin_subpackage("onednn", max_pin="x") }}
    requirements:
      host:
        - {{ pin_subpackage('onednn', exact=True) }}
      run:
        - {{ pin_subpackage('onednn', exact=True) }}
    about:
      home: https://github.com/oneapi-src/oneDNN
      license: Apache-2.0
      license_file: LICENSE
      summary: oneAPI Deep Neural Network Library (oneDNN)
      description: |
        oneAPI Deep Neural Network Library (oneDNN) is an open-source
        cross-platform performance library of basic building blocks for deep
        learning applications.

        oneDNN is intended for deep learning applications and framework
        developers interested in improving application performance.
        Deep learning practitioners should use one of the applications
        enabled with oneDNN.

        {% if dnnl_cpu_runtime == "omp" %}
        In this package oneDNN is built with the OpenMP CPU runtime.
        {% elif dnnl_cpu_runtime == "tbb" %}
        In this package oneDNN is built with the TBB CPU runtime.
        {% elif dnnl_cpu_runtime == "threadpool" %}
        In this package oneDNN is built with the Threadpool CPU runtime.
        oneDNN requires the user to implement a Threadpool interface to enable
        the library to perform computations using multiple threads.
        {% elif dnnl_cpu_runtime == "dpcpp" %}
        In this package oneDNN is built with the DPC++ CPU and GPU runtimes.
        {% endif %}

        For more information please read oneDNN developer guide:
        https://oneapi-src.github.io/oneDNN/
    test:
      commands:
        - exit 0

about:
  home: https://github.com/oneapi-src/oneDNN
  license: Apache-2.0
  license_file:
    - LICENSE
    - THIRD-PARTY-PROGRAMS
  summary: oneAPI Deep Neural Network Library (oneDNN)

extra:
  feedstock-name: onednn
  recipe-maintainers:
    - xhochy
    - densamoilov
    - spalicki
